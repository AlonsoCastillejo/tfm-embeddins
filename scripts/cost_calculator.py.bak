#!/usr/bin/env python3
"""
Calculadora de Costos de Embeddings OpenAI
==========================================

Analiza un archivo CSV y calcula el costo estimado de generar embeddings
para todos los registros usando la API de OpenAI.

Uso:
    python scripts/cost_calculator.py data/pisos_example.csv
    python scripts/cost_calculator.py data/pisos_final_capitales.csv --model large
"""

import sys
import os
import pandas as pd
import argparse
from typing import Dict, List, Tuple

# A√±adir src al path para imports
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from data_processor import DataProcessor

class EmbeddingCostCalculator:
    """Calculadora de costos para embeddings OpenAI"""

    # Precios oficiales OpenAI (por 1M tokens) - Septiembre 2025
    EMBEDDING_PRICES = {
        'text-embedding-3-small': 0.02,    # $0.02 por 1M tokens
        'text-embedding-3-large': 0.13,    # $0.13 por 1M tokens
        'text-embedding-ada-002': 0.10     # $0.10 por 1M tokens (legacy)
    }

    # Dimensiones de los embeddings
    EMBEDDING_DIMENSIONS = {
        'text-embedding-3-small': 1536,
        'text-embedding-3-large': 3072,
        'text-embedding-ada-002': 1536
    }

    def __init__(self):
        self.analysis_results = {}

    def analyze_csv(self, csv_path: str) -> Dict:
        """Analiza el CSV y calcula estad√≠sticas de texto"""
        print(f"üìÑ Analizando archivo: {csv_path}")
        print("=" * 60)

        # Cargar datos
        try:
            df = pd.read_csv(csv_path)
            print(f"‚úÖ Archivo cargado: {len(df)} registros")
        except Exception as e:
            print(f"‚ùå Error cargando archivo: {e}")
            return {}

        # Limpiar datos usando nuestro procesador
        df_clean = DataProcessor.clean_dataframe(df)
        print(f"‚úÖ Datos limpios: {len(df_clean)} registros v√°lidos")
        print(f"üìâ Registros eliminados: {len(df) - len(df_clean)}")

        # Generar textos descriptivos como lo hace el sistema real
        print("\nüî§ Generando textos descriptivos...")
        descriptive_texts = df_clean.apply(DataProcessor.build_descriptive_text, axis=1).tolist()

        # Analizar estad√≠sticas de texto
        text_stats = self._analyze_text_statistics(descriptive_texts)

        # Mostrar muestra de texto
        print(f"\nüìù Ejemplo de texto a procesar:")
        print("-" * 40)
        sample_text = descriptive_texts[0] if descriptive_texts else "N/A"
        print(f"{sample_text[:300]}...")
        print("-" * 40)

        self.analysis_results = {
            'csv_path': csv_path,
            'total_records': len(df),
            'valid_records': len(df_clean),
            'removed_records': len(df) - len(df_clean),
            'descriptive_texts': descriptive_texts,
            'text_stats': text_stats
        }

        return self.analysis_results

    def _analyze_text_statistics(self, texts: List[str]) -> Dict:
        """Analiza estad√≠sticas de los textos descriptivos"""
        if not texts:
            return {}

        # Calcular estad√≠sticas b√°sicas
        text_lengths = [len(text) for text in texts]
        word_counts = [len(text.split()) for text in texts]

        # Estimaci√≥n de tokens (aproximadamente 1 token = 4 caracteres para espa√±ol)
        # Esta es una estimaci√≥n conservadora - OpenAI usa tokenizaci√≥n m√°s precisa
        estimated_tokens = [len(text) // 3.5 for text in texts]  # Espa√±ol usa m√°s tokens que ingl√©s

        stats = {
            'total_texts': len(texts),
            'total_characters': sum(text_lengths),
            'total_words': sum(word_counts),
            'estimated_total_tokens': int(sum(estimated_tokens)),
            'avg_characters': sum(text_lengths) / len(texts),
            'avg_words': sum(word_counts) / len(texts),
            'avg_tokens': sum(estimated_tokens) / len(texts),
            'min_characters': min(text_lengths),
            'max_characters': max(text_lengths),
            'min_tokens': min(estimated_tokens),
            'max_tokens': max(estimated_tokens)
        }

        return stats

    def calculate_costs(self, model_name: str = 'text-embedding-3-large') -> Dict:
        """Calcula costos para diferentes modelos"""
        if not self.analysis_results:
            return {}

        text_stats = self.analysis_results['text_stats']
        estimated_tokens = text_stats['estimated_total_tokens']

        # Calcular costos para todos los modelos
        costs = {}
        for model, price_per_million in self.EMBEDDING_PRICES.items():
            cost = (estimated_tokens / 1_000_000) * price_per_million
            costs[model] = {
                'estimated_tokens': estimated_tokens,
                'price_per_million': price_per_million,
                'total_cost_usd': cost,
                'total_cost_eur': cost * 0.85,  # Conversi√≥n aproximada USD -> EUR
                'dimensions': self.EMBEDDING_DIMENSIONS[model]
            }

        return costs

    def print_detailed_analysis(self):
        """Imprime an√°lisis detallado de costos"""
        if not self.analysis_results:
            print("‚ùå No hay datos analizados")
            return

        results = self.analysis_results
        text_stats = results['text_stats']

        print(f"\nüìä AN√ÅLISIS DETALLADO DEL DATASET")
        print("=" * 60)

        # Estad√≠sticas del dataset
        print(f"üìÅ Archivo: {results['csv_path']}")
        print(f"üìà Registros totales: {results['total_records']:,}")
        print(f"‚úÖ Registros v√°lidos: {results['valid_records']:,}")
        print(f"‚ùå Registros eliminados: {results['removed_records']:,}")
        print(f"üìä Tasa de validez: {(results['valid_records']/results['total_records']*100):.1f}%")

        # Estad√≠sticas de texto
        print(f"\nüìù ESTAD√çSTICAS DE TEXTO")
        print("-" * 30)
        print(f"üìÑ Total caracteres: {text_stats['total_characters']:,}")
        print(f"üî§ Total palabras: {text_stats['total_words']:,}")
        print(f"üéØ Tokens estimados: {text_stats['estimated_total_tokens']:,}")
        print(f"üìè Promedio caracteres/texto: {text_stats['avg_characters']:.0f}")
        print(f"üìù Promedio palabras/texto: {text_stats['avg_words']:.0f}")
        print(f"üéØ Promedio tokens/texto: {text_stats['avg_tokens']:.0f}")
        print(f"üìê Rango tokens: {text_stats['min_tokens']:.0f} - {text_stats['max_tokens']:.0f}")

        # C√°lculo de costos
        costs = self.calculate_costs()

        print(f"\nüí∞ ESTIMACI√ìN DE COSTOS EMBEDDINGS")
        print("=" * 60)

        for model, cost_info in costs.items():
            print(f"\nü§ñ {model}")
            print(f"   üìè Dimensiones: {cost_info['dimensions']}")
            print(f"   üéØ Tokens estimados: {cost_info['estimated_tokens']:,}")
            print(f"   üíµ Precio por 1M tokens: ${cost_info['price_per_million']}")
            print(f"   üí∞ Costo total: ${cost_info['total_cost_usd']:.4f} USD")
            print(f"   üí∂ Costo total: ‚Ç¨{cost_info['total_cost_eur']:.4f} EUR")

            # Categorizaci√≥n de costo
            cost_category = self._categorize_cost(cost_info['total_cost_usd'])
            print(f"   üìä Categor√≠a: {cost_category}")

    def _categorize_cost(self, cost_usd: float) -> str:
        """Categoriza el costo para dar contexto"""
        if cost_usd < 0.01:
            return "üü¢ Muy Barato (< $0.01)"
        elif cost_usd < 0.10:
            return "üîµ Barato (< $0.10)"
        elif cost_usd < 1.00:
            return "üü° Moderado (< $1.00)"
        elif cost_usd < 10.00:
            return "üü† Caro (< $10.00)"
        else:
            return "üî¥ Muy Caro (> $10.00)"

    def compare_models(self):
        """Compara todos los modelos lado a lado"""
        costs = self.calculate_costs()

        print(f"\nüîç COMPARACI√ìN DE MODELOS")
        print("=" * 80)
        print(f"{'Modelo':<25} {'Dimensiones':<12} {'Costo USD':<12} {'Costo EUR':<12} {'Calidad'}")
        print("-" * 80)

        # Ordenar por costo
        sorted_models = sorted(costs.items(), key=lambda x: x[1]['total_cost_usd'])

        for model, info in sorted_models:
            quality = self._get_quality_rating(model)
            print(f"{model:<25} {info['dimensions']:<12} ${info['total_cost_usd']:<11.4f} "
                  f"‚Ç¨{info['total_cost_eur']:<11.4f} {quality}")

    def _get_quality_rating(self, model: str) -> str:
        """Devuelve rating de calidad para cada modelo"""
        quality_map = {
            'text-embedding-3-small': "‚≠ê‚≠ê‚≠ê",
            'text-embedding-3-large': "‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê",
            'text-embedding-ada-002': "‚≠ê‚≠ê"
        }
        return quality_map.get(model, "‚≠ê‚≠ê‚≠ê")

    def save_cost_report(self, output_path: str = None):
        """Guarda reporte detallado en archivo"""
        if not output_path:
            csv_name = os.path.basename(self.analysis_results['csv_path']).replace('.csv', '')
            output_path = f"cost_report_{csv_name}.txt"

        costs = self.calculate_costs()

        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("REPORTE DE COSTOS EMBEDDINGS OPENAI\n")
            f.write("=" * 50 + "\n\n")

            f.write(f"Archivo analizado: {self.analysis_results['csv_path']}\n")
            f.write(f"Registros v√°lidos: {self.analysis_results['valid_records']:,}\n")
            f.write(f"Tokens estimados: {self.analysis_results['text_stats']['estimated_total_tokens']:,}\n\n")

            f.write("COSTOS POR MODELO:\n")
            f.write("-" * 30 + "\n")

            for model, info in costs.items():
                f.write(f"{model}:\n")
                f.write(f"  - Costo: ${info['total_cost_usd']:.4f} USD / ‚Ç¨{info['total_cost_eur']:.4f} EUR\n")
                f.write(f"  - Dimensiones: {info['dimensions']}\n\n")

        print(f"üìÑ Reporte guardado en: {output_path}")

def main():
    """Funci√≥n principal"""
    parser = argparse.ArgumentParser(description="Calculadora de costos embeddings OpenAI")
    parser.add_argument("csv_file", help="Archivo CSV a analizar")
    parser.add_argument("--model", default="text-embedding-3-large",
                       choices=['text-embedding-3-small', 'text-embedding-3-large', 'text-embedding-ada-002'],
                       help="Modelo principal para an√°lisis detallado")
    parser.add_argument("--save-report", action="store_true", help="Guardar reporte en archivo")

    args = parser.parse_args()

    # Verificar que el archivo existe
    if not os.path.exists(args.csv_file):
        print(f"‚ùå Error: Archivo no encontrado: {args.csv_file}")
        return

    # Crear calculadora y analizar
    calculator = EmbeddingCostCalculator()

    # Analizar archivo
    results = calculator.analyze_csv(args.csv_file)
    if not results:
        return

    # Mostrar an√°lisis detallado
    calculator.print_detailed_analysis()

    # Comparar modelos
    calculator.compare_models()

    # Recomendaciones
    costs = calculator.calculate_costs()
    best_value = min(costs.items(), key=lambda x: x[1]['total_cost_usd'] / x[1]['dimensions'])
    best_quality = max(costs.items(), key=lambda x: x[1]['dimensions'])

    print(f"\nüéØ RECOMENDACIONES")
    print("=" * 30)
    print(f"üí∞ Mejor relaci√≥n calidad/precio: {best_value[0]}")
    print(f"‚≠ê M√°xima calidad: {best_quality[0]}")
    print(f"üèÉ Para pruebas r√°pidas: text-embedding-3-small")
    print(f"üöÄ Para producci√≥n: text-embedding-3-large")

    # Guardar reporte si se solicita
    if args.save_report:
        calculator.save_cost_report()

if __name__ == "__main__":
    main()